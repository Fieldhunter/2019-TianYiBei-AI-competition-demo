{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/Trainset/\"\n",
    "MASK_PATH = \"data/mask/\"\n",
    "IMAGE_SIZE = (150,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 核对通道位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def fit_keras_channels(batch, rows=IMAGE_SIZE[0], cols=IMAGE_SIZE[1]):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        batch = batch.reshape(batch.shape[0], 3, rows, cols)\n",
    "        input_shape = (3, rows, cols)\n",
    "    else:\n",
    "        batch = batch.reshape(batch.shape[0], rows, cols, 3)\n",
    "        input_shape = (rows, cols, 3)\n",
    "    \n",
    "    return batch, input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载和处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def load_data():\n",
    "    # 对mask图案的变换\n",
    "    def mask_process(make_img):\n",
    "        # 随机旋转\n",
    "        process_image = image.random_rotation(make_img,180,row_axis=0,col_axis=1,channel_axis=2,fill_mode='constant',cval=0)\n",
    "\n",
    "        # 随机平移\n",
    "        process_image = image.random_shift(process_image,0.2,0.3,row_axis=0,col_axis=1,channel_axis=2,fill_mode='constant',cval=0)\n",
    "\n",
    "        return process_image\n",
    "\n",
    "    # 对合成后图像的变换\n",
    "    def original_process(original_img):\n",
    "        # 随机旋转\n",
    "        process_image = image.random_rotation(original_img,180,row_axis=0,col_axis=1,channel_axis=2,fill_mode='constant',cval=0)\n",
    "            \n",
    "        # 随机投影变换\n",
    "        h, w = 150,150\n",
    "\n",
    "        ratio = np.random.normal(0.125, 0.075)\n",
    "        if ratio > 0.2:\n",
    "            ratio = 0.2\n",
    "        elif ratio < 0.05:\n",
    "            ratio = 0.05\n",
    "        pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n",
    "        pts2 = np.float32([[0, 0], [w, ratio*h], [0, h], [w, (1-ratio)*h]])\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        process_image = cv2.warpPerspective(process_image, M, (w, h))\n",
    "\n",
    "        # 随机平移\n",
    "        process_image = image.random_shift(process_image,0.2,0.3,row_axis=0,col_axis=1,channel_axis=2,fill_mode='constant',cval=0)\n",
    "\n",
    "        # 随机拉伸\n",
    "        ratio = np.random.normal(35, 15)\n",
    "        if ratio > 50:\n",
    "            ratio = 50\n",
    "        elif ratio < 20:\n",
    "            ratio = 20\n",
    "        process_image = image.random_shear(process_image,ratio,row_axis=0,col_axis=1,channel_axis=2)\n",
    "\n",
    "        return process_image\n",
    "    \n",
    "    # 掩膜合成\n",
    "    def make_mask(original_img, mask_img):\n",
    "        rows, cols, channels = mask_img.shape\n",
    "        roi = original_img[0:rows, 0:cols] \n",
    "        mask_img_gray = cv2.cvtColor(mask_img, cv2.COLOR_BGR2GRAY)# 颜色空间的转换\n",
    "\n",
    "        ret, mask = cv2.threshold(mask_img_gray, 20, 255, cv2.THRESH_BINARY)# 掩码 黑色\n",
    "        mask_inv = cv2.bitwise_not(mask)\n",
    "        img1_bg = cv2.bitwise_and(mask_img, mask_img, mask=mask)\n",
    "        img2_fg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "        dst = cv2.add(img1_bg, img2_fg)\n",
    "        original_img[0:rows, 0:cols] = dst\n",
    "        \n",
    "        return original_img\n",
    "\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    X_test = []\n",
    "    Y_test = []\n",
    "    mask_list = glob.glob(MASK_PATH + '*.jpg')\n",
    "    train_or_test = 0\n",
    "    count = 0\n",
    "    \n",
    "    for filename in glob.glob(DATA_PATH + '*.jpg'):\n",
    "        try:\n",
    "            # 先进行mask图案的处理，之后合成掩膜，再对合成后的图案进行处理\n",
    "            original_img = image.load_img(filename, target_size=IMAGE_SIZE)\n",
    "            original_img = np.uint8(image.img_to_array(original_img))\n",
    "            mask_img = image.load_img(random.choice(mask_list), target_size=IMAGE_SIZE)\n",
    "            mask_img = image.img_to_array(mask_img)\n",
    "            \n",
    "            # 以交叉的方式选取1501张图片为测试集\n",
    "            mask_img = np.uint8(mask_process(mask_img))\n",
    "            original_img = make_mask(original_img, mask_img)\n",
    "            original_img = original_process(np.float32(original_img))\n",
    "\n",
    "            if train_or_test == 1 and len(X_test) <= 1500:\n",
    "                X_test.append(original_img)\n",
    "                Y_test.append(filename.lstrip(DATA_PATH)[0])\n",
    "                train_or_test = 0\n",
    "            else:\n",
    "                X_train.append(original_img)\n",
    "                Y_train.append(filename.lstrip(DATA_PATH)[0])\n",
    "                train_or_test = 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行数值归一化和格式设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(X_train, Y_train, X_test, Y_test):\n",
    "    X_train = np.array(X_train, dtype=np.float32)\n",
    "    X_train = X_train / 255\n",
    "    X_test = np.array(X_test, dtype=np.float32)\n",
    "    X_test = X_test / 255\n",
    "    \n",
    "    X_train, input_shape = fit_keras_channels(X_train)\n",
    "    X_test, _ = fit_keras_channels(X_test)\n",
    "    \n",
    "    Y_train = np.asarray(Y_train).reshape(len(Y_train),1)\n",
    "    Y_test = np.asarray(Y_test).reshape(len(Y_test),1)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test, input_shape = process_data(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "\n",
    "OPT = 'adam'\n",
    "LOSS = 'binary_crossentropy'\n",
    "\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    N = K.sum(1 - y_true)\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    P = K.sum(y_true)\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "\n",
    "def model(input_shape, OPT, LOSS):\n",
    "    inputs = Input(shape=input_shape, name=\"inputs\")\n",
    "\n",
    "    conv1 = Conv2D(32, (3, 3), name=\"conv1\")(inputs)\n",
    "    relu1 = Activation('relu', name=\"relu1\")(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool1\")(relu1)\n",
    "    \n",
    "    conv2 = Conv2D(64, (3, 3), name = \"conv2\", padding='same')(pool1)\n",
    "    relu2 = Activation('relu', name=\"relu2\")(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool2\")(relu2)\n",
    "    \n",
    "    conv3 = Conv2D(64, (3, 3), name = \"conv3\", padding='same')(pool2)\n",
    "    relu3 = Activation('relu', name=\"relu3\")(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name=\"pool3\")(relu3)\n",
    "    \n",
    "    conv4 = Conv2D(128, (3, 3), name = \"conv4\")(pool3)\n",
    "    relu4 = Activation('relu', name=\"relu4\")(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), name=\"pool4\")(relu4)\n",
    "    \n",
    "    x = Flatten()(pool4)\n",
    "\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    model.compile(optimizer=OPT, loss=LOSS, metrics=[auc])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(input_shape, OPT, LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 1\n",
    "history = model.fit(X_train,\n",
    "                    Y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存模型和历史记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.gfile as gfile\n",
    "import pickle\n",
    "\n",
    "MODEL_DIR = './model/first/'\n",
    "MODEL_FORMAT = '.h5'\n",
    "HISTORY_DIR = './history/first/'\n",
    "HISTORY_FORMAT = '.history'\n",
    "\n",
    "filename_str = \"{}captcha_{}_{}_bs_{}_epochs_{}{}\"\n",
    "\n",
    "# 模型网络结构文件\n",
    "MODEL_VIS_FILE = 'captcha_classfication' + '.png'\n",
    "# 模型文件\n",
    "MODEL_FILE = filename_str.format(MODEL_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), MODEL_FORMAT)\n",
    "# 训练记录文件\n",
    "HISTORY_FILE = filename_str.format(HISTORY_DIR, OPT, LOSS, str(BATCH_SIZE), str(EPOCHS), HISTORY_FORMAT)\n",
    "def save_model(model, history):\n",
    "    if not gfile.Exists(MODEL_DIR):\n",
    "        gfile.MakeDirs(MODEL_DIR)\n",
    "\n",
    "    model.save(MODEL_FILE)\n",
    "\n",
    "    if gfile.Exists(HISTORY_DIR) == False:\n",
    "        gfile.MakeDirs(HISTORY_DIR)\n",
    "\n",
    "    with open(HISTORY_FILE, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "save_model(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
